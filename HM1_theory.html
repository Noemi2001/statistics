<!DOCTYPE html>
<html>
  <head>
      <title> HW 1 - Theory</title>
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/css/bootstrap.min.css" rel="stylesheet">
      <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/js/bootstrap.bundle.min.js"></script>
  </head>
  <body>
    <container stile="padding-left:5vw; padding-right:5vw; padding-top:5vh; self-align:center;">
      <h1 stile="text-align:center"> Homework 1 (Theoretical part) </h1>
      <p style="color:grey"> Assignment’s date: 5 October 2023 </p>
      <p style="color:grey"> Student ID: 1933541 </p>
      <p>
      <br>
      <h5><u>Question 1: What is Statistics and its relationship with other disciplines? Make examples of use in 
      cybersecurity.</u></h5>
      Statistics is a discipline or a science that collects and analyses data. There are many disciplines that 
      use statistics: 
      In Biology, the use of statistics is known as biostatistics or biometrics. It consists in collecting and 
      analysing the data received from experiments in order to decide results. Also, meteorology uses 
      statistics in stochastic-dynamic prediction and weather forecasting.
      Physics and Mathematics use probability theory and statistics dealing with the estimation of large 
      populations. For example, the phenomenological results of thermodynamics were developed using 
      the mechanics of statistics.
      Information technology uses statistics to predict particular outcomes. In particular, statistics is used 
      also in cybersecurity to identify intrusions and anomalous behaviour and therefore protect against 
      cyber-attacks. Using Statistics, machine learning and Big Data analytics were developed tools to 
      perform anomaly detection. Statistical techniques are used also in classification, data mining, 
      streaming data analysis, graph analysis, and machine learning.
      <br>
      <h5><u>Question 1-bis: What is the Difference between Descriptive and Inferential Statistics.</u></h5>
      The difference between Descriptive and Inferential Statistics is that: Descriptive Statistics consists in 
      observe and analyse data from an entire known population. Inferential Statistics consists in observe 
      a sample from a larger, unknown population. It involves making conclusions about the larger 
      population based on the analysis of the sample. 
      <br>
      <h5><u>Question 2: Describe the concepts of variable, attribute, population, sample and dataset</u></h5>
      • Attribute: is a general abstract concept. In fact, it is any characteristic that can be measured in a 
      study.
      • Variable: is a specific value that can be assigned to an attribute refers to a particular individual. It 
      can also vary among individuals and from one observation to another.
      • Population: is a set of similar items called statistical units by which is possible to collect data that 
      are necessary for a specific survey.
      • Sample: is a population’s subset. It must be representative and not biased, this means that the 
      shape of the sample’s result has to be similar to the population one.
      • Dataset: is a collection of data that is usually represented by a table. It is composed by some 
      columns that are the attribute observed, and many rows which are the data collected from every 
      statistical unit.
      • Level of measurement: Level of measurement refers to the process of categorizing data based on 
      their characteristics and properties. It represents the different set of values that a variable can 
      assume.
      <br>
      <h5><u>Question 3: Briefly describe the main sampling techniques</u></h5>
      The sampling techniques are used to choose a representative sample from a population. Reducing 
      the number of individuals in a study reduces the cost and workload.
      There are different sampling techniques and they can be subdivided into two groups: probability 
      sampling and non-probability sampling. In probability (random) sampling, you start with a complete 
      sampling frame of all individuals from which you select your sample. In this way, all individuals have a 
      chance of being chosen for the sample, so it is possible to have a generalise results of the study. In 
      non-probability sampling, you do not start with a complete sampling frame, so some individuals have 
      no chance of being selected. This method is usually cheaper. Some examples are: 
      1. Simple random sampling (Probability): consists to give an identificatory number to each individual 
      in a population, and then use a table of random numbers to decide which individuals have to be
      included. Whit this technique, each individual is chosen entirely by chance and each member of 
      the population has an equal probability, of being selected. 
      2. Clustered sampling (Probability): the population is subdivided in subgroups, called cluster, that 
      are used as the sampling unit and they are randomly selected to be included in the study. Cluster 
      sampling can be efficient when a study takes place over a wide geographical region. But, if the 
      chosen clusters are not representative of the population, the risk of bias will increase.
      3. Convenience sampling (Non-Probability): all participants are selected based on availability and 
      willingness to take part. There is a significant risk of bias and the sample may not be 
      representative.
      4. Snowball sampling (Non-Probability): Consists to ask to existing subjects nominate other
      individuals known to them, so the sample increases in size like a rolling snowball. Snowball 
      sampling can be effective when a sampling frame is difficult to identify. However, there is a 
      significant risk of selection bias.
      <h5><u>Question 4: Briefly describe the main experiment designs.</u></h5>
      The experiment design, is the design of any task that aims to describe and explain the variation of 
      information under conditions that are hypothesized to reflect the variation.
      Some experiment designs are:
      1. Bayesian experimental design provides a general probability-theoretical framework from which 
      other theories on experimental design can be derived. It is based on Bayesian inference to 
      interpret the data collected during the experiment. This allows accounting for both any prior 
      knowledge on the parameters to be determined as well as uncertainties in observations.
      2. Optimal designs are a class of experimental designs that are optimal respect to some statistical
      criterion. This classification was created by Kirstine Smith and it allow parameters to be estimated
      without bias and with minimum variance. Also it can reduce the costs of experimentation, 
      because non-optimal design requires a greater number of experimental runs
      to estimate the parameters with the same precision as an optimal design. 
      </p>
      <br>
      <p>
      Bibliography:
      1. Lecture notes from the lesson of the statistics course
      2. Statistics.com: Link 2
      3. Udemy.com: Link 3
      4. Imperial college of London: Link 4
      5. Wikipedia: Link 5
      6. Health knowledge: Link 
      </p>
    </container>
  </body>
</html>
